{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b487417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hello World!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Hello World!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b703b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu126\n",
      "True\n",
      "1\n",
      "0\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9d54fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from glob import glob\n",
    "import os\n",
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2187751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'gen-ai-animal-dataset' dataset.\n",
      "‚úÖ Dataset is ready at: /content/animal_data\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"] = \"tejaskumarvurs\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"80fbc5d540819df3b4666ae5df969af9\"\n",
    "\n",
    "path = kagglehub.dataset_download(\"tejaskumarvurs/gen-ai-animal-dataset\")\n",
    "\n",
    "dest = \"/content/animal_data\"\n",
    "if not os.path.exists(dest):\n",
    "    shutil.copytree(path, dest)\n",
    "\n",
    "print(f\"‚úÖ Dataset is ready at: {dest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c8a211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gen-ai-animal-dataset\n"
     ]
    }
   ],
   "source": [
    "!find / -name \"gen-ai-animal-dataset\" -type d 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f51fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/content/dataset': File exists\n",
      "/content/dataset\n",
      "ls: cannot access '/content/dataset/Camel': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Force a link from the hidden system path to your visible content folder\n",
    "!ln -s /root/.cache/kagglehub/datasets/tejaskumarvurs/gen-ai-animal-dataset/versions/1 /content/dataset\n",
    "\n",
    "# Now check if Colab can 'see' into that shortcut\n",
    "!ls /content/dataset | head -n 5\n",
    "\n",
    "!ls /content/dataset/Camel | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a694740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files accessible for T4 training: 29071\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/content/dataset\"\n",
    "\n",
    "def count_files(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])\n",
    "\n",
    "print(f\"Total files accessible for T4 training: {count_files(DATA_PATH)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c640ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Path exists!\n",
      "Items inside '/content/dataset': ['Deer', 'Panda', 'Turkey', 'Goat', 'Canary']\n",
      "üìÅ Found subfolders (Classes). Use datasets.ImageFolder(path)\n"
     ]
    }
   ],
   "source": [
    "path = \"/content/dataset\"\n",
    "\n",
    "if os.path.exists(path):\n",
    "    contents = os.listdir(path)\n",
    "    print(f\"‚úÖ Path exists!\")\n",
    "    print(f\"Items inside '{path}': {contents[:5]}\") # Shows first 5 items\n",
    "    \n",
    "    # Check if the first item is a file or a folder\n",
    "    if len(contents) > 0:\n",
    "        first_item = os.path.join(path, contents[0])\n",
    "        if os.path.isdir(first_item):\n",
    "            print(\"üìÅ Found subfolders (Classes). Use datasets.ImageFolder(path)\")\n",
    "        else:\n",
    "            print(\"üñºÔ∏è Found direct files. Use a custom Dataset class.\")\n",
    "else:\n",
    "    print(f\"‚ùå Path NOT found: {path}\")\n",
    "    print(\"Checking /content/ to see what is actually there:\")\n",
    "    print(os.listdir(\"/content/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0718721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, size=64):\n",
    "        # Fixed the typo: \"**/*.jpg\" instead of \"**/*,jpg\"\n",
    "        self.files = glob(os.path.join(root, \"**/*.jpg\"), recursive=True)\n",
    "        \n",
    "        if len(self.files) == 0:\n",
    "            print(f\"‚ö†Ô∏è Warning: No .jpg files found in {root}. Check path or extensions.\")\n",
    "            \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.CenterCrop(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3) # Scales to [-1, 1]\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
    "        return self.transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38ec7806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/dataset/Deer/4fe91d2f25f3b6a5.jpg', '/content/dataset/Deer/511aa4fa584803b3.jpg', '/content/dataset/Deer/a760f2fee588211e.jpg', '/content/dataset/Deer/bba443efc42d285e.jpg', '/content/dataset/Deer/f73679d797ac75a8.jpg', '/content/dataset/Deer/5eef9054a0123096.jpg', '/content/dataset/Deer/5c52a9fc6ec207f1.jpg', '/content/dataset/Deer/2455b8585d5bf0d9.jpg', '/content/dataset/Deer/1fdb9545a37ae8a9.jpg', '/content/dataset/Deer/09ab94e77f37e1c1.jpg', '/content/dataset/Deer/c65823cfb39ef048.jpg', '/content/dataset/Deer/027928cdac94d62d.jpg', '/content/dataset/Deer/7e7c478ee979f3c2.jpg', '/content/dataset/Deer/e1213ee2ce7c3e9b.jpg', '/content/dataset/Deer/8cd7ebd5d9ecde8f.jpg', '/content/dataset/Deer/99606eaef7120ad8.jpg', '/content/dataset/Deer/dc60f8e75d4e4668.jpg', '/content/dataset/Deer/a966b561b9ff2ad1.jpg', '/content/dataset/Deer/d878d864f26a8e67.jpg', '/content/dataset/Deer/71c05c33211b1416.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 20 file paths to see if they look correct\n",
    "test_ds = ImageDataset(\"/content/dataset\")\n",
    "print(test_ds.files[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a459767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, z_dim=512, w_dim=512):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(8):\n",
    "            layers.append(nn.Linear(w_dim, w_dim))\n",
    "            layers.append(nn.LeakyReLU())\n",
    "        self.mapping = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        z = z / z.norm(dim=1, keepdim=True)\n",
    "        return self.mapping(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e79ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, w_dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_ch, in_ch, 3, 3))\n",
    "        self.style = nn.Linear(w_dim, in_ch)\n",
    "        self.noise_strength = nn.Parameter(torch.zeros(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_ch))\n",
    "    \n",
    "    def forward(self, x, w, noise):\n",
    "        b, c, h, w_ = x.shape\n",
    "        style = self.style(w).view(b, 1, c, 1, 1)\n",
    "        weight = self.weight.unsqueeze(0) * style\n",
    "        weight = weight.view(-1, c, 3, 3)\n",
    "\n",
    "        x = x.view(1, -1, h, w_)\n",
    "        x= F.conv2d(x, weight, padding=1, groups=b)\n",
    "        x = x.view(b, -1, h, w_)\n",
    "\n",
    "        x = x + self.noise_strength * noise\n",
    "        return x + self.bias.view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bcdb7bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2144498945.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMappingNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=512, w_dim=512):\n",
    "        super().__init__()\n",
    "        self.mapping = MappingNetwork(z_dim, w_dim)\n",
    "\n",
    "        self.const = nn.Parameter(torch.randn(1, 512, 4, 4))\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            StyleConv(512, 512, w_dim),\n",
    "            StyleConv(512, 256, w_dim),\n",
    "            StyleConv(256, 128, w_dim),\n",
    "            StyleConv(128, 64, w_dim),\n",
    "          ])\n",
    "        \n",
    "        self.to_rgb = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.mapping(z)\n",
    "        x = self.const.repeat(z.size(0), 1, 1, 1)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "            noise = torch.randn(x.size(0), 1, x.size(2), x.size(3), device=x.device)\n",
    "\n",
    "            x = layer(x, w, noise)\n",
    "            x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        return torch.tanh(self.to_rgb(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52080e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 4, 2, 1),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            block(3, 64),\n",
    "            block(64, 128),\n",
    "            block(128, 256),\n",
    "            block(256, 512),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*4*4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43f61629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Penalty(D, real, fake):\n",
    "    alpha = torch.rand(real.size(0), 1, 1, 1).to(device)\n",
    "    interp = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "    out = D(interp)\n",
    "\n",
    "    grads = torch.autograd.grad(\n",
    "        outputs=out,\n",
    "        inputs=interp,\n",
    "        grad_outputs=torch.ones_like(out),\n",
    "        create_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    return ((grads.norm(2, dim=1) - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c25856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    path = \"/content/dataset\"  # Update this path as needed\n",
    "    dataset = ImageDataset(path, size=64)\n",
    "    print(f\"‚úÖ Dataset loaded with {len(dataset)} images.\")\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    G = Generator().to(device)\n",
    "    D = Discriminator().to(device)\n",
    "\n",
    "    g_opt = torch.optim.Adam(G.parameters(), lr=1e-4, betas=(0.0, 0.99))\n",
    "    d_opt = torch.optim.Adam(D.parameters(), lr=1e-4, betas=(0.0, 0.99))\n",
    "\n",
    "    for epoch in range(50):\n",
    "        for i, real in enumerate(loader):\n",
    "            real = real.to(device)\n",
    "            z = torch.randn(real.size(0), 512).to(device)\n",
    "            fake = G(z)\n",
    "\n",
    "            d_loss = D(fake).mean() - D(real).mean()\n",
    "            gp = Gradient_Penalty(D, real, fake)\n",
    "            d_total = d_loss + 10 * gp\n",
    "\n",
    "            d_opt.zero_grad()\n",
    "            d_total.backward()\n",
    "            d_opt.step()\n",
    "\n",
    "            if i % 5 == 0:\n",
    "                g_loss = -D(G(z)).mean()\n",
    "                g_opt.zero_grad()\n",
    "                g_loss.backward()\n",
    "                g_opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            samples = G(torch.randn(16, 512).to(device))\n",
    "            save_image(samples, f\"samples/epoch_{epoch}.png\", normalize=True)\n",
    "\n",
    "        print(f\"Epoch {epoch} | D: {d_total.item():.3f} | G: {g_loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05d55b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1990237592.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-1350851622.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/dataset\"\u001b[0m  \u001b[0;31m# Update this path as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ Dataset loaded with {len(dataset)} images.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e767acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
